# LLM Provider Configuration
# 
# DETECTION PRIORITY ORDER (as implemented in ProviderClient.get_provider_for_model):
#
# 1. CLIPROXYAPI PRECEDENCE:
#    If CLIPROXYAPI_BASE_URL is set in the environment, the system first attempts to match 
#    the model name against the 'cliproxyapi' models list using a two-way substring match.
#
# 2. GLM FAMILY SPECIAL RESOLUTION:
#    Models containing 'glm-*' variants are routed to the Z.ai provider ('zai').
#    This repo treats Z.ai as the sole GLM provider SSOT (no open.bigmodel.cn endpoints).
#
# 3. GENERIC ORDERED MATCHING:
#    If no specific resolution occurs, the system iterates through the 'providers' 
#    dictionary below in the order defined. The first provider whose 'models' list 
#    contains the model name as a substring will be selected.
#
# NOTE: Provider order in this file determines selection priority for generic matching!

providers:
  # Official DeepSeek API. Used for deepseek-chat and deepseek-reasoner models.
  deepseek:
    base_url: "https://api.deepseek.com/v1"
    env_key: "DEEPSEEK_API_KEY"
    timeout: 180
    vision: false
    models:
      - deepseek-chat
      - deepseek-reasoner

  # Z.ai API (api.z.ai).
  # Primary provider for GLM-4.x models.
  zai:
    base_url: "https://api.z.ai/api/paas/v4"
    env_key: "ZAI_API_KEY"
    timeout: 180
    vision: true
    models:
      - glm-4.5
      - glm-4.5-air
      - glm-4.5-flash
      - glm-4.5v
      - glm-4.6
      - glm-4.6-flash
      - glm-4.6v
      - glm-4.6v-flash
      - glm-4.7
      - glm-4.7-flash

  # Antigravity Proxy API. Handles Claude, Gemini, and GPT models via unified proxy.
  # Prioritized if CLIPROXYAPI_BASE_URL is set; otherwise matched via generic loop.
  cliproxyapi:
    base_url: ""  # Configured via CLIPROXYAPI_BASE_URL
    env_key: "CLIPROXYAPI_API_KEY"
    timeout: 120
    vision: true
    models:
      # Antigravity Claude
      - claude-opus-4-5-thinking
      - claude-sonnet-4-5-thinking
      - claude-sonnet-4-5
      - claude-sonnet-4-20250514
      - claude-3.5-sonnet
      # Antigravity Gemini
      - gemini-2.5-pro
      - gemini-2.5-flash
      - gemini-2.5-flash-lite
      - gemini-3-pro-preview
      - gemini-3-flash
      # Antigravity GPT
      - gpt-4o
      - gpt-4o-mini
      - gpt-oss-120b-medium

  # Ollama Cloud API. Used for open-source models like Llama, Qwen, Mistral.
  # Matched via generic ordered matching loop.
  ollama-cloud:
    base_url: "https://api.ollama.com/v1"
    env_key: "OLLAMA_CLOUD_API_KEY"
    timeout: 120
    vision: true
    models:
      - llama3.3
      - llama3.2
      - llama3.1
      - llama3
      - qwen2.5
      - qwen2.5-coder
      - mistral
      - mixtral
      - deepseek-r1
      - deepseek-v3
      - phi4
      - gemma2
      - codellama
      - llama3.2-vision
      - llava

  # MiniMax API. Used for MiniMax-M2.1 models.
  # Matched via generic ordered matching loop.
  minimax:
    base_url: "https://api.minimax.io/v1"
    env_key: "MINIMAX_API_KEY"
    timeout: 120
    vision: false
    models:
      - MiniMax-M2.1

# Default timeout for providers without explicit timeout (fallback)
default_timeout: 120

vision_patterns:
  - gpt-4o
  - claude-3-opus
  - claude-3-sonnet
  - claude-3.5-sonnet
  - claude-4
  - claude-sonnet-4
  - gemini-2.5-pro
  - gemini-3-pro
  - gemini-3-flash
  - glm-4.5v
  - glm-4.6v
  - glm-4v
  - llama3.2-vision
  - llava
