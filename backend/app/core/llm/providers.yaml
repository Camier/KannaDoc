# LLM Provider Configuration
# 
# DETECTION PRIORITY ORDER (as implemented in ProviderClient.get_provider_for_model):
#
# 1. CLIPROXYAPI PRECEDENCE:
#    If CLIPROXYAPI_BASE_URL is set in the environment, the system first attempts to match 
#    the model name against the 'cliproxyapi' models list using a two-way substring match.
#
# 2. GLM FAMILY SPECIAL RESOLUTION:
#    Models containing 'glm-*' variants are routed to the Z.ai provider ('zai').
#    This repo treats Z.ai as the sole GLM provider SSOT (no open.bigmodel.cn endpoints).
#
# 3. GENERIC ORDERED MATCHING:
#    If no specific resolution occurs, the system iterates through the 'providers' 
#    dictionary below in the order defined. The first provider whose 'models' list 
#    contains the model name as a substring will be selected.
#
# NOTE: Provider order in this file determines selection priority for generic matching!

providers:
  # Official DeepSeek API. Used for deepseek-chat and deepseek-reasoner models.
  deepseek:
    base_url: "https://api.deepseek.com/v1"
    env_key: "DEEPSEEK_API_KEY"
    timeout: 180
    vision: false
    models:
      - deepseek-chat
      - deepseek-reasoner

  # Z.ai API (api.z.ai).
  # Primary provider for GLM-4.x models.
  zai:
    base_url: "https://api.z.ai/api/paas/v4"
    env_key: "ZAI_API_KEY"
    timeout: 180
    vision: true
    models:
      - glm-4.5
      - glm-4.5-air
      - glm-4.5-flash
      - glm-4.5v
      - glm-4.6
      - glm-4.6-flash
      - glm-4.6v
      - glm-4.6v-flash
      - glm-4.7
      - glm-4.7-flash

  # Antigravity Proxy API (via Codex CLI). Handles Claude and Gemini models.
  # NOTE: OpenAI models (gpt-4o) are NOT available through codex cli.
  cliproxyapi:
    base_url: ""  # Configured via CLIPROXYAPI_BASE_URL
    env_key: "CLIPROXYAPI_API_KEY"
    timeout: 120
    vision: true
    models:
      # Claude (Anthropic via Antigravity)
      # Keep aligned with what the Antigravity proxy exposes in this environment.
      - claude-opus-4-6-thinking
      - claude-sonnet-4-5-thinking
      - claude-sonnet-4-5
      - claude-sonnet-4-20250514
      - claude-3.5-sonnet
      # Gemini (Google via Antigravity)
      - gemini-2.5-pro
      - gemini-2.5-flash
      - gemini-2.5-flash-lite
      - gemini-3-pro-preview
      - gemini-3-flash

  # Ollama Cloud API. Open-source models hosted on Ollama infrastructure.
  ollama-cloud:
    base_url: "https://ollama.com/v1"
    env_key: "OLLAMA_CLOUD_API_KEY"
    timeout: 120
    vision: true
    models:
      # GPT-OSS (Ollama's open-source GPT variants)
      - gpt-oss:120b
      - gpt-oss:20b
      # Llama family
      - llama3.3
      - llama3.3:70b
      - llama3.2
      - llama3.2:1b
      - llama3.2:3b
      - llama3.1
      - llama3.1:8b
      - llama3.1:70b
      - llama3.1:405b
      - llama3
      - llama3:8b
      - llama3:70b
      # Qwen family
      - qwen2.5
      - qwen2.5:0.5b
      - qwen2.5:1.5b
      - qwen2.5:3b
      - qwen2.5:7b
      - qwen2.5:14b
      - qwen2.5:32b
      - qwen2.5:72b
      - qwen2.5-coder
      - qwen2.5-coder:1.5b
      - qwen2.5-coder:7b
      - qwen2.5-coder:32b
      - qwq
      # Mistral family
      - mistral
      - mistral:7b
      - mixtral
      - mixtral:8x7b
      - mixtral:8x22b
      # DeepSeek (Ollama-hosted, not official API)
      - deepseek-r1
      - deepseek-r1:1.5b
      - deepseek-r1:7b
      - deepseek-r1:8b
      - deepseek-r1:14b
      - deepseek-r1:32b
      - deepseek-r1:70b
      - deepseek-r1:671b
      - deepseek-v3
      # Other models
      - phi4
      - phi4:14b
      - gemma2
      - gemma2:2b
      - gemma2:9b
      - gemma2:27b
      - codellama
      - codellama:7b
      - codellama:13b
      - codellama:34b
      - codellama:70b
      # Vision models
      - llama3.2-vision
      - llama3.2-vision:11b
      - llama3.2-vision:90b
      - llava
      - llava:7b
      - llava:13b
      - llava:34b

  # MiniMax API. Used for MiniMax-M2.1 models.
  # Matched via generic ordered matching loop.
  minimax:
    base_url: "https://api.minimax.io/v1"
    env_key: "MINIMAX_API_KEY"
    timeout: 120
    vision: false
    models:
      - MiniMax-M2.1

# Default timeout for providers without explicit timeout (fallback)
default_timeout: 120

vision_patterns:
  - gpt-4o
  - claude-3-opus
  - claude-3-sonnet
  - claude-3.5-sonnet
  - claude-4
  - claude-sonnet-4
  - gemini-2.5-pro
  - gemini-3-pro
  - gemini-3-flash
  - glm-4.5v
  - glm-4.6v
  - glm-4v
  - llama3.2-vision
  - llava
