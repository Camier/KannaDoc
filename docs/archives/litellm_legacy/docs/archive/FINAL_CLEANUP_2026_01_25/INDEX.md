# Documentation Index

**Production-Ready LiteLLM Proxy** | Aligned with [Official Best Practices](https://docs.litellm.ai/docs/proxy/prod)

## ğŸš€ Quick Start

### New Users
1. **[`PRODUCTION_SETUP.md`](../PRODUCTION_SETUP.md)** - Complete production setup guide
2. **[`README.md`](../README.md)** - Repository overview & quick start
3. **[`.env.example`](../.env.example)** - Environment template

### Production Configuration
- **[`OFFICIAL_DOCS_ALIGNMENT.md`](../OFFICIAL_DOCS_ALIGNMENT.md)** - Detailed production settings explanation
- **`config.yaml`** (root) - Main configuration (Single Source of Truth)
- **`.env`** (root) - Secrets & API keys

---

## ğŸ“– Core Documentation

### Operations
- **`LITELLM_OPS.md`** - Operational runbook (comprehensive)
- **`OPERATIONAL_BASELINE.md`** - Operational baseline (SSOT)
- **`MODEL_MANAGEMENT.md`** - How to add/modify models
- **`DOCKER_DEPLOYMENT.md`** - Docker deployment guide
- **`PRODUCTION_DEPLOYMENT.md`** - Production deployment procedures

### Reference
- **`REPO_STRUCTURE.md`** - Repository structure & conventions
- **`INFRA_KNOWLEDGE.md`** - Infrastructure details
- **`HARDENING.md`** - Security hardening guide

---

## ğŸ” Generated Reports

Location: `docs/generated/`

- **`MODEL_CAPABILITIES.md`** - Per-model capability matrix
- **`MODEL_INVENTORY_REPORT.md`** - Model inventory sync report
- **`.last_refresh_attempt`** - Last capability refresh timestamp

---

## ğŸ›  Operational Commands

### Health & Validation

```bash
# Comprehensive health checks
just check

# Probe all models (1-token test)
just probe

# Health check script
./bin/health_check.py

# Model inventory report
./bin/model_inventory_report.py

# Capability matrix (probes all models)
./bin/probe_capabilities.py --scope all --fetch-docs
# Output: generated/MODEL_CAPABILITIES.md + state/model_capabilities.json
```

### Service Management

```bash
# Start/stop
just run        # Start services
just restart    # Restart proxy (apply config changes)
just logs       # Follow logs

# Docker commands
docker-compose up -d
docker-compose down
docker-compose logs -f litellm
```

### Monitoring

```bash
# Worker processes
docker-compose exec litellm ps aux | grep gunicorn

# Health endpoints
curl http://localhost:4001/health/liveliness
curl http://localhost:4000/health

# Metrics (Prometheus)
curl http://localhost:4000/metrics
```

**Note:** After `docker-compose restart litellm`, the proxy takes ~10-30s to accept connections.

## Environment / Secrets Policy
- Do **not** print secrets in logs or docs.
- Use placeholders like `sk-***` in examples.

## Key Management
- Official CLI usage: `OFFICIAL_CLI_GUIDE.md`
- Official virtual keys docs: https://docs.litellm.ai/docs/proxy/virtual_keys

## Logging
- Use `docker-compose logs -f litellm` for live logs.
- Archive logs under `logs/archive/` if you create one.

## Runtime outputs (volatile)
- `logs/` and `state/` are runtime outputs; safe to prune non-active files.
- If you create an `artifacts/` directory, store one-off scans there.

## Admin UI
- Official UI docs: https://docs.litellm.ai/docs/proxy/ui

## â€œThinkingâ€ / reasoning notes
- `THINKING_MODELS.md`

## Generated inventories / reports
- `generated/HF_TRENDING_INVENTORY.md`
- `HF_TRENDING_MODELS.md` (input list for `bin/hf_trending_inventory.py`)
- `generated/HF_SCOUT_REPORT.md` (generated by `./bin/hf_scout_models.py`)
- `generated/MODEL_CAPABILITIES.md`
- `generated/MODEL_INVENTORY_REPORT.md`
- `generated/VALIDATION_REPORT.md`
- Archived analysis + snapshots: `archive/analysis/`

## Legacy / historical
- `PRODUCTION_DEPLOYMENT.md` (legacy placeholder)
- `start_sh_functions.md` (legacy placeholder)

---

## ğŸ“ Directory Structure

```
/LAB/@litellm/
â”œâ”€â”€ config.yaml              # Main configuration (SSOT)
â”œâ”€â”€ docker-compose.yml       # Container orchestration
â”œâ”€â”€ .env                     # Secrets & API keys
â”œâ”€â”€ PRODUCTION_SETUP.md      # Complete setup guide
â”œâ”€â”€ OFFICIAL_DOCS_ALIGNMENT.md  # Production settings explained
â”œâ”€â”€ README.md                # Repository overview
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ INDEX.md             # This file
â”‚   â”œâ”€â”€ LITELLM_OPS.md       # Operational runbook
â”‚   â”œâ”€â”€ MODEL_MANAGEMENT.md  # Model configuration guide
â”‚   â”œâ”€â”€ generated/           # Auto-generated reports
â”‚   â””â”€â”€ archive/             # Historical documentation
â”‚
â”œâ”€â”€ bin/
â”‚   â”œâ”€â”€ health_check.py      # Health validation
â”‚   â”œâ”€â”€ model_inventory_report.py
â”‚   â”œâ”€â”€ probe_capabilities.py
â”‚   â””â”€â”€ ops/                 # Operational scripts
â”‚
â”œâ”€â”€ state/                   # Runtime state (volatile)
â”œâ”€â”€ logs/                    # Container logs (volatile)
â””â”€â”€ migrations/              # Database migrations
```

---

## ğŸ”‘ Security & Management

- **Environment Template:** `.env.example` (root)
- **Virtual Keys:** https://docs.litellm.ai/docs/proxy/virtual_keys
- **Security Policy:** Never print secrets in logs/docs (use `sk-***` placeholders)

---

## ğŸ”— Official References

- [Official LiteLLM Docs](https://docs.litellm.ai/)
- [Production Best Practices](https://docs.litellm.ai/docs/proxy/prod)
- [Configuration Settings](https://docs.litellm.ai/docs/proxy/config_settings)
- [Admin UI Documentation](https://docs.litellm.ai/docs/proxy/ui)

---

## ğŸ“¦ Archive

- **`archive/2026-01-24-before-consolidation/`** - Pre-consolidation status docs
- **`archive/`** - Previous maintenance reports and analysis

---

## ğŸ”Œ Provider Configuration

### Main Guides
- **[`../PROVIDER_SETUP.md`](../PROVIDER_SETUP.md)** - Complete provider setup guide
- **[`providers/QUICK_REFERENCE.md`](./providers/QUICK_REFERENCE.md)** - Quick reference card

### Provider-Specific
- **`providers/`** - Provider-specific guides and setup docs
  - Gemini setup guides
  - OpenCode integration example
  - Historical documentation

### Quick Setup Commands

```bash
# Add API keys to .env
vim .env

# Required minimum: OLLAMA_API_KEY
# Recommended: OLLAMA_API_KEY, GEMINI_API_KEY, VOYAGE_API_KEY

# Restart services
docker-compose restart litellm
sleep 30

# Verify providers
just probe
```

### Get API Keys

- **Ollama Cloud:** https://ollama.com (free tier)
- **Google Gemini:** https://aistudio.google.com/ (15 RPM free)
- **Voyage AI:** https://www.voyageai.com/ (testing free)
- **Cohere:** https://cohere.com/ (free tier)
