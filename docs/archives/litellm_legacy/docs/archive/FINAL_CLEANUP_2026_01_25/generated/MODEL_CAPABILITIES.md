# Model Capabilities Matrix

Generated: 2026-01-21T13:06:17+00:00
Proxy: http://127.0.0.1:9100

This document is auto-generated by `bin/probe_capabilities.py`.
It reflects actual observed behavior through the running LiteLLM proxy.

---

## Legend

- `✓` = Supported (HTTP 200, expected response)
- `✗` = Not supported (non-200 or missing expected data)
- `?` = Unknown / inconclusive

---

## Capabilities

| Model | Mode | Chat | Stream | Tools (auto) | Tools (req) | Embed | Rerank |
|-------|------|------|--------|--------------|-------------|-------|--------|
| chat-default | chat | ✗ | ? | ? | ? | ? | ? |
| chat-gemma3-1b-ollama | chat | ✗ | ? | ? | ? | ? | ? |
| chat-hermes-3-llama-3.1-8b | chat | ✗ | ? | ? | ? | ? | ? |
| chat-llama3.2-1b-ollama | chat | ✗ | ? | ? | ? | ? | ? |
| chat-mistral-7b-ollama | chat | ✗ | ? | ? | ? | ? | ? |
| chat-qwen2.5-0.5b-vllm | chat | ✗ | ? | ? | ? | ? | ? |
| chat-qwen3-coder-30b-ollama | chat | ✗ | ? | ? | ? | ? | ? |
| embed-arctic-l-v2 | chat | ✗ | ? | ? | ? | ? | ? |
| local-rerank | chat | ✗ | ? | ? | ? | ? | ? |
| ollama-embeddings | chat | ✗ | ? | ? | ? | ? | ? |
| qwen3-coder-480b-cloud | chat | ✗ | ? | ? | ? | ? | ? |
| vision-qwen3-vl-4b-ollama | chat | ✗ | ? | ? | ? | ? | ? |

---

## Probe Details

### Chat
- Tests: Basic `v1/chat/completions` request
- Success criterion: HTTP 200 with non-empty content

### Stream
- Tests: Same request with `stream: true`
- Success criterion: HTTP 200 with SSE `data:` events

### Tools (auto)
- Tests: Request with `tools` array, `tool_choice: auto`
- Success criterion: HTTP 200 with `tool_calls` in response

### Tools (required)
- Tests: Request with `tool_choice: required`
- Success criterion: HTTP 200 with `tool_calls` in response

### Embed
- Tests: `v1/embeddings` request
- Success criterion: HTTP 200 with embedding vector

### Rerank
- Tests: `v1/rerank` request (Jina-style API)
- Success criterion: HTTP 200 with results

