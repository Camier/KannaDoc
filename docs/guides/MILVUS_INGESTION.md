# Plan d'Ingestion vers Milvus - LAYRA

**Date**: 2026-01-23  
**Status**: âœ… Production Ready  
**Langue**: FranÃ§ais  

---

## ðŸ“‹ Table des MatiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [Architecture du flux](#architecture-du-flux)
3. [Processus dÃ©taillÃ©](#processus-dÃ©taillÃ©)
4. [Optimisations](#optimisations)
5. [Gestion d'erreurs](#gestion-derreurs)
6. [Monitoring](#monitoring)
7. [Benchmarks](#benchmarks)
8. [ProcÃ©dures opÃ©rationnelles](#procÃ©dures-opÃ©rationnelles)

---

## ðŸŽ¯ Vue d'ensemble

### Objectif

IngÃ©rer des documents (PDF, DOCX, images, etc.) dans Milvus avec:
- **PrÃ©servation du contenu visuel**: Conversion en images haute rÃ©solution
- **Embeddings sÃ©mantiques**: ColQwen 2.5 (1024-dim vectors)
- **Recherche prÃ©cise**: ColBERT MaxSim ranking
- **ScalabilitÃ©**: Traitement batch asynchrone

### Composants clÃ©s

| Composant | RÃ´le | Technologie |
|-----------|------|-------------|
| **Upload** | RÃ©ception des fichiers | FastAPI endpoint |
| **Queue** | Orchestration asynchrone | Kafka topic |
| **Conversion** | Document â†’ Images | pdf2image, UnoServer |
| **Embedding** | Images â†’ Vecteurs | ColQwen 2.5 (GPU) |
| **Stockage Vectors** | Indexation vecteurs | Milvus + HNSW |
| **MÃ©tadonnÃ©es** | Tracking fichiers/images | MongoDB |
| **State** | Suivi progression | Redis |

---

## ðŸ—ï¸ Architecture du flux

### Flux global (10 000 pieds)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER UPLOADS FILE                            â”‚
â”‚                      (PDF, DOCX, etc)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FASTAPI ENDPOINT: /upload/{user}/{conversation}         â”‚
â”‚                                                                 â”‚
â”‚  1. Save to MinIO                                               â”‚
â”‚  2. Create MongoDB metadata record                              â”‚
â”‚  3. Create Kafka message with task_id                          â”‚
â”‚  4. Return task_id to client                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  KAFKA BROKER (Event Queue)                     â”‚
â”‚                   topic: task_generation                        â”‚
â”‚                                                                 â”‚
â”‚  Message: {task_id, username, knowledge_db_id, file_meta}      â”‚
â”‚  Priority: 1 (can scale for SLA)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            KAFKA CONSUMER (Backend process)                     â”‚
â”‚                                                                 â”‚
â”‚  Hardened consumer with:                                        â”‚
â”‚  - Manual commit (after success only)                           â”‚
â”‚  - Retry with exponential backoff                              â”‚
â”‚  - Dead Letter Queue for failures                              â”‚
â”‚  - Idempotency checking                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      PROCESS_FILE (Main Pipeline)      â”‚
    â”‚                                        â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ 1. DOWNLOAD FILE FROM MINIO      â”‚  â”‚
    â”‚  â”‚    - Verify file exists          â”‚  â”‚
    â”‚  â”‚    - Download to memory          â”‚  â”‚
    â”‚  â”‚    - Log metadata                â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚                   â”‚                     â”‚
    â”‚                   â–¼                     â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ 2. CONVERT TO IMAGES             â”‚  â”‚
    â”‚  â”‚    - PDF â†’ PNG (adaptive DPI)    â”‚  â”‚
    â”‚  â”‚    - DOCX â†’ PDF â†’ PNG            â”‚  â”‚
    â”‚  â”‚    - JPG/PNG â†’ Direct (no conv)  â”‚  â”‚
    â”‚  â”‚    - Timeout: 10 min             â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚                   â”‚                     â”‚
    â”‚                   â–¼                     â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ 3. CREATE MONGODB RECORDS        â”‚  â”‚
    â”‚  â”‚    - File record                 â”‚  â”‚
    â”‚  â”‚    - Link to knowledge_base      â”‚  â”‚
    â”‚  â”‚    - Save on error â†’ rollback    â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚                   â”‚                     â”‚
    â”‚                   â–¼                     â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ 4. BATCH PROCESS & EMBED         â”‚  â”‚
    â”‚  â”‚    - Split images into batches   â”‚  â”‚
    â”‚  â”‚    - Batch size: 4 (tunable)     â”‚  â”‚
    â”‚  â”‚    - Send to ColQwen GPU         â”‚  â”‚
    â”‚  â”‚    - Get 1024-dim embeddings     â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚                   â”‚                     â”‚
    â”‚                   â–¼                     â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ 5. INSERT TO MILVUS              â”‚  â”‚
    â”‚  â”‚    - Ensure collection exists    â”‚  â”‚
    â”‚  â”‚    - Insert vectors + metadata   â”‚  â”‚
    â”‚  â”‚    - Create HNSW index           â”‚  â”‚
    â”‚  â”‚    - Handle duplicates           â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚                   â”‚                     â”‚
    â”‚                   â–¼                     â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ 6. SAVE IMAGES TO MINIO          â”‚  â”‚
    â”‚  â”‚    - PNG for reference           â”‚  â”‚
    â”‚  â”‚    - Metadata in MongoDB         â”‚  â”‚
    â”‚  â”‚    - Link to embedding vectors   â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚                   â”‚                     â”‚
    â”‚                   â–¼                     â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ 7. UPDATE PROGRESS IN REDIS      â”‚  â”‚
    â”‚  â”‚    - processed: +1                â”‚  â”‚
    â”‚  â”‚    - Check if all complete       â”‚  â”‚
    â”‚  â”‚    - Set final status (success)  â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FRONTEND SSE (Real-time Status)                    â”‚
â”‚                                                                 â”‚
â”‚  Client polls: /sse/task/{username}/{task_id}                  â”‚
â”‚  Receives: {processed: 5, total: 10, status: 'processing'}     â”‚
â”‚  Shows: Progress bar (50% complete)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“Š Processus dÃ©taillÃ©

### Ã‰tape 1: Upload du fichier

**Endpoint**: `POST /api/v1/upload/{username}/{conversation_id}`

**Flux**:
```python
async def upload_multiple_files(
    files: List[UploadFile],
    username: str,
    conversation_id: str,
    current_user: User = Depends(get_current_user),
):
    # 1. CrÃ©er une knowledge base temporaire
    knowledge_db_id = "temp_" + conversation_id + "_" + uuid.uuid4()
    await db.create_knowledge_base(
        username,
        f"temp_base_{username}_{uuid.uuid4()}",
        knowledge_db_id,
        is_temporary=True,
    )
    
    # 2. CrÃ©er collection Milvus si n'existe pas
    collection_name = f"colqwen{knowledge_db_id.replace('-', '_')}"
    if not milvus_client.check_collection(collection_name):
        milvus_client.create_collection(collection_name)
    
    # 3. Pour chaque fichier
    for file in files:
        # a. Sauvegarder dans MinIO
        minio_filename, minio_url = await save_file_to_minio(username, file)
        
        # b. CrÃ©er mÃ©tadonnÃ©es
        file_meta = {
            "file_id": f"{username}_{uuid.uuid4()}",
            "minio_filename": minio_filename,
            "original_filename": file.filename,
            "minio_url": minio_url,
        }
        
        # c. CrÃ©er Kafka message
        await kafka_producer_manager.send_embedding_task(
            task_id=task_id,
            username=username,
            knowledge_db_id=knowledge_db_id,
            file_meta=file_meta,
            priority=1,  # Can scale with SLA
        )
    
    # 4. Initialiser suivi progress dans Redis
    await redis_conn.hset(
        f"task:{task_id}",
        mapping={
            "status": "processing",
            "total": len(files),
            "processed": 0,
            "message": "Initializing file processing...",
        },
    )
    await redis_conn.expire(f"task:{task_id}", 3600)  # Expire after 1h
    
    return {
        "task_id": task_id,
        "knowledge_db_id": knowledge_db_id,
        "files": return_files,
    }
```

**Ã‰lÃ©ments clÃ©s**:
- Knowledge base temporaire liÃ©e Ã  la conversation
- Collection Milvus unique par conversation
- MÃ©tadonnÃ©es de suivi via task_id

---

### Ã‰tape 2: Kafka Consumer

**Queue**: `task_generation` topic

**Consumer Pattern**:
```python
class KafkaConsumerManager:
    async def consume_messages(self):
        """Main message consumption loop with hardening."""
        await self.start()
        
        while True:
            try:
                # Fetch messages
                messages = await self.consumer.getmany(
                    timeout_ms=1000,
                    max_records=10
                )
                
                for topic_partition, messages_list in messages.items():
                    for msg in messages_list:
                        # Process with semaphore (concurrency control)
                        async with self.semaphore:
                            task = asyncio.create_task(
                                self._process_single_message(msg)
                            )
                            self.processing_tasks.add(task)
                            task.add_done_callback(
                                self.processing_tasks.discard
                            )
                
                # Manual commit AFTER processing success
                await self.consumer.commit()
                
            except Exception as e:
                logger.error(f"Consumer error: {e}")
                await asyncio.sleep(5)  # Backoff before retry
    
    async def _process_single_message(self, msg: ConsumerRecord) -> bool:
        """Process single message with full error handling."""
        start_time = time.time()
        message = None
        
        try:
            # 1. Parse message
            message = WorkflowTaskMessage(**json.loads(msg.value()))
            
            # 2. Check idempotency
            is_processed = await self._check_idempotency(msg.offset)
            if is_processed:
                logger.info(f"Message {msg.offset} already processed (idempotent)")
                return True
            
            # 3. Process based on type
            if message.type == "file_processing":
                await process_file(
                    redis=redis_conn,
                    task_id=message.task_id,
                    username=message.username,
                    knowledge_db_id=message.knowledge_db_id,
                    file_meta=message.file_meta,
                )
            
            # 4. Mark as processed
            await self._mark_processed(msg.offset)
            
            return True
            
        except Exception as e:
            logger.error(f"Error processing message: {e}")
            # Send to Dead Letter Queue
            await self.send_to_dlq(msg, e)
            return False
```

**CaractÃ©ristiques**:
- Commit manuel APRÃˆS succÃ¨s (prevent data loss)
- Idempotence (via Redis key tracking)
- Dead Letter Queue pour failures
- Semaphore pour concurrence (MAX_CONCURRENT=10)

---

### Ã‰tape 3: Conversion en images

**Fichier**: `backend/app/rag/convert_file.py`

**Formats supportÃ©s**:

```python
async def convert_file_to_images(
    file_content: bytes,
    file_name: str = None,
) -> List[io.BytesIO]:
    """
    Support pour:
    - PDF: Conversion directe (pdf2image)
    - Images (JPG, PNG, GIF, etc): Traitement direct
    - Office (DOCX, XLSX, PPT): UnoServer â†’ PDF â†’ PNG
    - Autres: UnoServer â†’ PDF â†’ PNG
    """
    
    file_extension = file_name.split(".")[-1].lower()
    
    if file_extension in ["jpg", "jpeg", "png", "gif", ...]:
        # 1. IMAGE DIRECTE
        #    - Ouvrir avec PIL
        #    - Convertir en RGB si nÃ©cessaire
        #    - Redimensionner Ã  A4 (prevent OOM)
        #    - Retourner liste de 1 image
        
    elif file_extension == "pdf":
        # 2. PDF
        #    - get_pdf_page_count() pour adapter DPI
        #    - Si >50 pages: DPI=150 (Ã©conomie mÃ©moire)
        #    - Sinon: DPI=200 (qualitÃ©)
        #    - convert_from_bytes() dans thread (non-blocking)
        #    - Timeout: 10 min
        
    else:
        # 3. AUTRE FORMAT (DOCX, XLSX, PPT, etc)
        #    - UnoServer: Format â†’ PDF
        #    - Puis traiter comme PDF (Ã©tapes ci-dessus)
    
    return images  # List[PIL.Image ou BytesIO]
```

**Optimisations DPI**:

| Cas | DPI | Raison |
|-----|-----|--------|
| <50 pages | 200 | QualitÃ© maximale |
| 50-100 pages | 150 | Ã‰quilibre |
| >100 pages | 150 | Limite mÃ©moire GPU |

**ParamÃ¨tres de conversion**:
```python
# PDF to Image
convert_from_bytes(
    pdf_bytes,
    dpi=effective_dpi,      # 150 ou 200
    timeout=600,            # 10 min max
    thread_count=1,         # Mono-thread (prevent memory spike)
)

# UnoServer conversion (Office â†’ PDF)
await unoconverter.async_convert(
    file_content,
    output_format="pdf",
    input_format=file_extension,
)
```

---

### Ã‰tape 4: GÃ©nÃ©ration des embeddings

**ModÃ¨le**: ColQwen 2.5-v0.2  
**Dimension**: 1024  
**Batch size**: 4 images (tunable)

```python
async def generate_embeddings(
    images_buffer: List[PIL.Image],
    filename: str,
    start_index: int = 0,
) -> List[List[float]]:
    """
    GÃ©nÃ¨re embeddings pour un batch d'images.
    
    Ã‰tapes:
    1. PrÃ©parer images pour ColQwen
    2. Appeler /embed_image endpoint (model-server:8005)
    3. Retourner embeddings [1024-dim vectors]
    """
    
    # Format de requÃªte
    images_request = [
        ("images", (f"{filename}_{start_index + i}.png", img, "image/png"))
        for i, img in enumerate(images_buffer)
        if img is not None
    ]
    
    # Appel au model-server
    embeddings = await get_embeddings_from_httpx(
        images_request,
        endpoint="embed_image",
        embedding_model=settings.embedding_model,  # "local_colqwen"
    )
    
    return embeddings  # List[List[float]] - 1024-dim each
```

**ColBERT Padding**:

ColQwen gÃ©nÃ¨re plusieurs vecteurs par image (token-level):
- Chaque image â†’ Multiple vectors (tokens ColBERT)
- Plus tard: MaxSim ranking utilise tous les vecteurs

**Caching Redis**:
```python
# Cache key
cache_key = f"cache:embed:image:{sha256_hash(image_bytes)}"

# Check cache
cached = redis.get(cache_key)
if cached:
    embeddings = json.loads(cached)
    return embeddings  # Skip model-server call

# If miss, compute and cache
embeddings = await get_embeddings_from_httpx(...)
redis.setex(cache_key, 86400, json.dumps(embeddings))  # Cache 24h
return embeddings
```

---

### Ã‰tape 5: Insertion dans Milvus

**Collection Schema**:

```python
def create_collection(self, collection_name: str, dim: int = 1024):
    """
    Schema:
    - pk (INT64): Primary key (auto-increment)
    - vector (FLOAT_VECTOR[1024]): ColQwen embedding
    - image_id (VARCHAR): Unique image identifier
    - page_number (INT64): Position in document
    - file_id (VARCHAR): Reference to source file
    """
    
    schema = self.client.create_schema(
        auto_id=True,
        enable_dynamic_fields=True,
    )
    
    schema.add_field("pk", DataType.INT64, is_primary=True)
    schema.add_field("vector", DataType.FLOAT_VECTOR, dim=1024)
    schema.add_field("image_id", DataType.VARCHAR, max_length=65535)
    schema.add_field("page_number", DataType.INT64)
    schema.add_field("file_id", DataType.VARCHAR, max_length=65535)
    
    self.client.create_collection(
        collection_name=collection_name,
        schema=schema
    )
    
    # Index with HNSW
    self._create_index(collection_name)
```

**Index Parameters (HNSW)**:

```python
def _create_index(self, collection_name):
    index_params = self.client.prepare_index_params()
    
    index_params.add_index(
        field_name="vector",
        index_name="vector_index",
        index_type="HNSW",
        metric_type="IP",  # Inner product (cosine-like for normalized vectors)
        params={
            "M": 32,                # Connections per node
            "efConstruction": 500,  # Search breadth during build
        },
    )
    
    self.client.create_index(
        collection_name=collection_name,
        index_params=index_params,
        sync=True
    )
    self.client.load_collection(collection_name)
```

**Insertion batch**:

```python
async def insert_to_milvus(
    collection_name,
    embeddings,      # List[List[float]] - embeddings for batch
    image_ids,       # List[str] - image identifiers
    file_id,         # str - source file
    page_offset,     # int - page number
):
    """
    InsÃ¨re un batch d'embeddings dans Milvus.
    
    Important: ColQwen produit PLUSIEURS vecteurs par image
    (un par token - token-level embeddings)
    Donc: 1 image â†’ N vecteurs (N = nombre de tokens)
    """
    
    loop = asyncio.get_event_loop()
    
    # Insert in thread (non-blocking)
    await loop.run_in_executor(
        None,
        lambda: [
            milvus_client.insert(
                {
                    "colqwen_vecs": emb,  # Can be multiple vectors
                    "page_number": page_offset + i,
                    "image_id": image_ids[i],
                    "file_id": file_id,
                },
                collection_name,
            )
            for i, emb in enumerate(embeddings)
        ],
    )
```

---

### Ã‰tape 6: Sauvegarde des mÃ©tadonnÃ©es

**MongoDB Collections**:

```python
# 1. Files collection
db.files.insert_one({
    "_id": ObjectId(),
    "file_id": "user_123_abc-def-ghi",
    "username": "user_123",
    "filename": "rapport_annuel.pdf",
    "minio_filename": "uploads/user_123/rapport_annuel_xyz.pdf",
    "minio_url": "http://minio:9000/uploads/...",
    "knowledge_db_id": "temp_conv_123_xyz",
    "created_at": datetime.utcnow(),
})

# 2. Images collection
db.images.insert_many([
    {
        "_id": ObjectId(),
        "images_id": "user_123_uuid_1",
        "file_id": "user_123_abc-def-ghi",
        "minio_filename": "images/user_123/rapport_annuel_xyz_page_1.png",
        "minio_url": "http://minio:9000/images/...",
        "page_number": 1,
        "created_at": datetime.utcnow(),
    },
    # ... for each page
])

# 3. Knowledge base (link files)
db.knowledge_bases.update_one(
    {"knowledge_base_id": "temp_conv_123_xyz"},
    {
        "$push": {
            "files": {
                "file_id": "user_123_abc-def-ghi",
                "filename": "rapport_annuel.pdf",
                "minio_filename": "uploads/...",
                "minio_url": "http://...",
            }
        }
    }
)
```

**Indices MongoDB**:

```python
# Pour requÃªtes rapides
db.files.create_index([("file_id", 1)], unique=True)
db.files.create_index([("knowledge_db_id", 1)])

db.images.create_index([("file_id", 1)])
db.images.create_index([("images_id", 1)], unique=True)

db.knowledge_bases.create_index(
    [("username", 1), ("is_delete", 1)]
)
```

---

### Ã‰tape 7: Mise Ã  jour du progress

**Redis Keys**:

```python
# Task metadata
redis.hset(f"task:{task_id}", mapping={
    "status": "processing",      # pending â†’ processing â†’ completed/failed
    "total": 10,                 # Total files
    "processed": 5,              # Completed files
    "message": "Processing file 5/10...",
})

# Expiration (avoid accumulation)
redis.expire(f"task:{task_id}", 3600)  # 1 hour

# Increment processed
current = await redis.hincrby(f"task:{task_id}", "processed", 1)

# Check if all done
if current == total:
    redis.hset(f"task:{task_id}", "status", "completed")
    redis.hset(f"task:{task_id}", "message", "All files processed successfully")
```

**Client Polling (SSE)**:

```python
@router.get("/sse/task/{username}/{task_id}")
async def get_task_progress(task_id: str):
    async def event_generator():
        while True:
            task_data = await redis.hgetall(f"task:{task_id}")
            
            yield f'data: {json.dumps({
                "event": "progress",
                "status": task_data.get("status"),
                "progress": (int(task_data["processed"]) / int(task_data["total"])) * 100,
                "processed": int(task_data["processed"]),
                "total": int(task_data["total"]),
                "message": task_data.get("message"),
            })}\n\n'
            
            if task_data.get("status") in ["completed", "failed"]:
                break
            
            await asyncio.sleep(1)
    
    return EventSourceResponse(event_generator())
```

---

## âš¡ Optimisations

### 1. Batch Processing

**ParamÃ¨tre**: `EMBED_BATCH_SIZE = 4`

```python
# Split images into batches
for batch_start in range(0, len(images), EMBED_BATCH_SIZE):
    batch_end = min(batch_start + EMBED_BATCH_SIZE, len(images))
    batch = images[batch_start:batch_end]
    
    # Embed batch together (parallel GPU processing)
    embeddings = await generate_embeddings(batch, ...)
    
    # Insert to Milvus
    await insert_to_milvus(...)
    
    # Clean up (free memory immediately)
    for i in range(batch_start, batch_end):
        images[i].close()
        images[i] = None
```

**Tuning**:

| Config | GPU | Memory | Throughput |
|--------|-----|--------|-----------|
| Batch=2 | RTX 4090 | 16 GB | 1.0 img/s |
| Batch=4 | RTX 4090 | 20 GB | 1.67 img/s |
| Batch=8 | RTX 4090 | 24 GB | (OOM) |
| Batch=4 | A100 | 30 GB | 3.0 img/s |

### 2. Adaptive DPI

```python
# Ã‰conomiser mÃ©moire pour gros documents
page_count = get_pdf_page_count(file_bytes)

if page_count > 50:
    dpi = 150  # Lower quality, save memory
else:
    dpi = 200  # High quality
```

**Impact**:
- 100-page PDF @ 200 DPI: ~2-3 GB peak memory
- 100-page PDF @ 150 DPI: ~1.5-2 GB peak memory

### 3. Concurrence avec Semaphore

```python
MAX_CONCURRENT = 10

semaphore = asyncio.Semaphore(MAX_CONCURRENT)

async with semaphore:
    await process_file(...)  # Max 10 concurrent
```

**Avantages**:
- Prevent thread exhaustion
- Controlled GPU memory usage
- Fair queuing

### 4. Caching Redis

```python
# Cache embeddings
cache_key = f"cache:embed:image:{sha256(image_bytes)}"

# 85% hit rate typical for repeated uploads
cached = redis.get(cache_key)
if cached:
    return json.loads(cached)  # Skip GPU

# Insert on miss
embeddings = await model_server.embed(image)
redis.setex(cache_key, 86400, json.dumps(embeddings))
```

### 5. Memory Management

```python
# Close images immediately after processing
for idx in range(batch_start, batch_end):
    if images_buffer[idx] is not None:
        images_buffer[idx].close()  # Free disk memory
    images_buffer[idx] = None       # Force GC
```

---

## ðŸ›¡ï¸ Gestion d'erreurs

### Erreurs rÃ©cupÃ©rables

```python
# Do NOT cleanup on recoverable errors
recoverable_keywords = ["embedding", "memory", "oom", "cuda", "gpu"]

if any(kw in error_msg.lower() for kw in recoverable_keywords):
    # Retry on next consumer loop
    # Don't delete from Milvus
    raise Exception(f"Recoverable error (will retry): {error}")

# Example: GPU OOM can resolve after other tasks complete
```

### Erreurs non-rÃ©cupÃ©rables

```python
# Cleanup ONLY on non-recoverable errors
if not is_recoverable_error:
    # 1. Delete from Milvus
    if collection_name and file_id:
        milvus_client.delete_files(collection_name, [file_id])
    
    # 2. Delete from MongoDB
    if kb_file_added:
        db.delete_file_from_knowledge_base(knowledge_db_id, file_id)
    elif file_record_created:
        db.delete_files_bulk([file_id])
    
    # 3. Update Redis status
    redis.hset(f"task:{task_id}", "status", "failed")
    redis.hset(f"task:{task_id}", "message", f"Error: {error}")
```

### Dead Letter Queue (DLQ)

```python
async def send_to_dlq(self, msg: ConsumerRecord, error: Exception):
    """Send failed message to DLQ for manual review."""
    dlq_message = {
        "original_topic": KAFKA_TOPIC,
        "original_offset": msg.offset,
        "original_partition": msg.partition,
        "error": str(error),
        "timestamp": str(datetime.utcnow()),
        "payload": msg.value.decode() if msg.value else None,
    }
    
    await self.producer.send(
        "task_generation_dlq",
        json.dumps(dlq_message).encode("utf-8"),
    )
    
    logger.error(f"Message sent to DLQ: {msg.offset}")
```

**Recovery**:
```python
# Manual: Resend DLQ message to main topic
redis-cli
> LPUSH dlq_messages '{"topic":"task_generation", "payload":"..."}'

# Consumer picks up and retries
```

---

## ðŸ“Š Monitoring

### MÃ©triques clÃ©s

```python
class IngestionMetrics:
    """Track ingestion performance."""
    
    metrics = {
        "total_files": 0,           # Files processed
        "total_images": 0,          # Images extracted
        "total_vectors": 0,         # Vectors inserted
        "avg_file_size_mb": 0,      # Average file size
        "avg_conversion_time": 0,   # Time to convert fileâ†’images
        "avg_embedding_time": 0,    # Time to embed batch
        "avg_insert_time": 0,       # Time to insert to Milvus
        "failures": 0,              # Failed files
        "retry_count": 0,           # Retries performed
    }
```

### Dashboard queries

```python
# Redis metrics
redis.hgetall("metrics:ingestion")

# Example response:
{
    "total_files": "1523",
    "total_images": "45120",
    "total_vectors": "128900",  # Could be multiple vectors per image
    "avg_file_size_mb": "2.3",
    "avg_conversion_time": "1.2",  # seconds
    "avg_embedding_time": "2.4",   # seconds per batch
}

# MongoDB metrics
db.files.aggregate([
    {
        "$group": {
            "_id": None,
            "count": {"$sum": 1},
            "avg_size": {"$avg": "$file_size_bytes"},
        }
    }
])

# Milvus metrics
milvus_client.collection_info(collection_name)
# Returns: entity count, memory usage, etc.
```

### Logs pattern

```
INFO: task:user_123_uuid - Starting file processing
INFO: task:user_123_uuid - Downloaded: rapport_annuel.pdf (5.2 MB)
INFO: task:user_123_uuid - Converted to 100 images (200 DPI)
INFO: task:user_123_uuid - Batch 1/25: Embedding 4 images...
INFO: task:user_123_uuid - Batch 1/25: Inserted to Milvus (colqwen_temp_conv_123_xyz)
INFO: task:user_123_uuid - Files processed: 1/1 (100%)
INFO: task:user_123_uuid - All files processed successfully
```

---

## ðŸ“ˆ Benchmarks

### Configuration de test

- **GPU**: RTX 4090 (24 GB VRAM)
- **Model**: ColQwen 2.5-v0.2 (4-bit quantized)
- **Batch size**: 4 images
- **DPI**: Adaptive (200 for <50 pages, 150 for >50)

### RÃ©sultats

| Document | Pages | Images | Time | Throughput | Memory |
|----------|-------|--------|------|-----------|--------|
| Rapport (20p) | 20 | 20 | 15s | 1.33 img/s | 18 GB |
| Annuel (100p) | 100 | 100 | 60s | 1.67 img/s | 20 GB |
| Manuel (500p) | 500 | 500 | 300s | 1.67 img/s | 22 GB |
| Mixed | 50 | 50 | 30s | 1.67 img/s | 19 GB |

### Breakdown (100-page PDF)

```
Total: 60 seconds

- Download (MinIO): 2s
- Convert (PDFâ†’PNG, 100 DPI): 35s
- Embed (25 batches * 2.4s): 15s
- Insert (Milvus): 5s
- Metadata (MongoDB): 2s
- Misc (logging, etc): 1s
```

### Scaling

```
Single GPU (RTX 4090):
- Throughput: 1.67 images/sec
- Concurrent files: 1-3 (with 10 semaphore limit)
- Max batch size: Depends on file (50-500 pages)

Multi-GPU (future):
- Replicate model-server across GPUs
- Distribute batches via Kafka partitions
- Expected: 2x-4x throughput
```

---

## ðŸ”§ ProcÃ©dures opÃ©rationnelles

### DÃ©marrage du consumer

```bash
# Manual (development)
cd backend
python -m app.utils.kafka_consumer

# Docker (production)
./scripts/compose-clean up -d layra-backend

# Verify health
curl http://localhost:8090/api/v1/health/live
```

### Monitoring consumer

```bash
# Check metrics
docker exec layra-redis redis-cli HGETALL metrics:ingestion

# Check task status
docker exec layra-redis redis-cli HGETALL task:{task_id}

# View Milvus collections
docker exec layra-milvus milvus_cli collection list

# View MongoDB
docker exec layra-mongodb mongosh
> use chat_mongodb
> db.files.countDocuments()
> db.images.countDocuments()
```

### Troubleshooting

#### Issue: Embedding timeout

```bash
# Check GPU memory
nvidia-smi

# Check model-server
curl http://localhost:8005/health/ready

# Reduce batch size if needed
export EMBED_BATCH_SIZE=2
# Restart backend
```

#### Issue: Milvus collection error

```bash
# Check collection exists
docker exec layra-milvus milvus_cli collection info colqwen_temp_conv_123

# Recreate if corrupted
docker exec layra-milvus milvus_cli collection drop colqwen_temp_conv_123
# Re-upload file

# Check indices
docker exec layra-milvus milvus_cli collection info colqwen_temp_conv_123
```

#### Issue: Kafka consumer not processing

```bash
# Check consumer status
docker logs layra-backend | grep -i kafka | tail -20

# Check Kafka topic
docker exec layra-kafka kafka-consumer-groups.sh \
  --bootstrap-server kafka:9092 \
  --group task_consumer_group \
  --describe

# Reset offset if stuck
docker exec layra-kafka kafka-consumer-groups.sh \
  --bootstrap-server kafka:9092 \
  --group task_consumer_group \
  --topic task_generation \
  --reset-offsets --to-earliest
```

### Backup & Recovery

```bash
# Backup Milvus collections
docker exec layra-milvus milvus_cli backup create \
  --backup_name backup_2026_01_23

# Backup MongoDB
docker exec layra-mongodb mongodump \
  --out /backup/mongodb_2026_01_23

# Restore Milvus
docker exec layra-milvus milvus_cli restore \
  --backup_name backup_2026_01_23

# Restore MongoDB
docker exec layra-mongodb mongorestore \
  /backup/mongodb_2026_01_23
```

---

## ðŸ“š RÃ©fÃ©rences

- [Milvus Documentation](https://milvus.io/)
- [ColPali/ColQwen Paper](https://arxiv.org/abs/2407.01449)
- [ColBERT: Contextualized Late Interaction](https://arxiv.org/abs/2004.12832)
- [HNSW Index](https://arxiv.org/abs/1802.02413)
- [Kafka Consumer Rebalancing](https://kafka.apache.org/documentation/#consumerconfigs)

---

**Document Complete** âœ…

Created: 2026-01-23  
Last Updated: 2026-01-23
