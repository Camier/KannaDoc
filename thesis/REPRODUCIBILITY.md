# LAYRA Thesis Reproducibility Guide

> **Generated**: 2026-02-06
> **Corpus Version**: V3.1 (53,800 relationships)
> **Evaluation Framework**: MRR, NDCG, P@K, R@K with threshold enforcement

---

## Quick Start

```bash
# 1. Validate corpus integrity
cd backend && PYTHONPATH=. python3 scripts/datalab/validate_corpus.py

# 2. Run evaluation
PYTHONPATH=. python3 scripts/datalab/rag_eval.py \
  --collection ethnopharmacology_v2 \
  --ground-truth app/eval/config/ground_truth.json \
  --top-k 5 \
  --output ../thesis/results/eval_$(date +%Y%m%d).json

# 3. Verify thresholds
python3 -c "import json; d=json.load(open('thesis/results/eval_*.json')); print('Passed:', d['passed'])"
```

---

## Corpus Specification

| Artifact | Count | Location |
|----------|-------|----------|
| Source PDFs | 129 | `backend/data/pdfs/` |
| Extractions | 129 | `backend/data/extractions/` |
| Documents with relationships | 128 | 99.2% coverage |
| Total relationships | 53,800 | V3.1 schema |
| Entity types | 17 | See AGENTS.md Section 3 |
| Relationship types | 16 | See AGENTS.md Section 3 |

### Corpus Manifest

Each document is tracked with SHA256 hash in `thesis/config/corpus_manifest.jsonl`:

```json
{"filename": "...", "sha256": "...", "file_id": "..."}
```

To verify corpus integrity:
```bash
cd backend/data/pdfs
for pdf in *.pdf; do
  sha256sum "$pdf"
done | diff - ../corpus_manifest.jsonl
```

---

## Evaluation Configuration

### Thresholds (`thesis/config/thresholds.yaml`)

| Metric | Development | Production |
|--------|-------------|------------|
| Recall@K | ≥ 0.60 | ≥ 0.80 |
| MRR | ≥ 0.50 | ≥ 0.75 |
| p95 Latency | ≤ 5000ms | ≤ 2000ms |
| Error Rate | ≤ 1% | ≤ 0.5% |

### Ground Truth

- **Dataset**: 20 curated questions in `dataset_dev.jsonl`
- **Ground truth mapping**: `ground_truth.json` (question_id → doc_ids)
- **Manifest**: `ground_truth_manifest.yaml` with version info

---

## Entity Extraction

### V3.1 Schema

**17 Entity Types** across 6 domains:

| Domain | Types |
|--------|-------|
| Ethnographic | Culture, UseRecord, TraditionalUse, Preparation |
| Botanical | Taxon, PlantPart, RawMaterial |
| Chemical | CompoundClass, Compound |
| Pharmacological | Target, Effect |
| Clinical | Condition, Evidence, Study, Dosage, AdverseEvent |
| Product | Product |

**16 Relationship Types**: HAS_USE, INVOLVES, HAS_PART, TRANSFORMS, CONTAINS, HAS_CLASS, ACTS_ON, PRODUCES, TREATS, SUGGESTS, CAUSES, INTERACTS_WITH, HAS_EVIDENCE, STUDIES, TESTED_AT, REPORTS

### Extraction Pipeline

```bash
# Re-run extraction (if needed)
cd backend
PYTHONPATH=. python3 scripts/datalab/extract_deepseek.py \
  --input-dir data/extractions \
  --concurrency 10 \
  --force
```

---

## Infrastructure Requirements

| Component | Version/Config |
|-----------|----------------|
| Python | 3.12+ |
| Milvus | 2.3+ (HNSW index) |
| MongoDB | 6.0+ |
| Redis | 7.0+ |
| DeepSeek API | deepseek-chat model |

### HNSW Index Parameters

| Parameter | Value |
|-----------|-------|
| M | 48 |
| efConstruction | 1024 |
| Metric | COSINE |

---

## Verification Commands

```bash
# Corpus integrity
cd backend && PYTHONPATH=. python3 scripts/datalab/validate_corpus.py

# Relationship count
cd backend/data/extractions && \
for f in */entities.json; do jq '.relationships|length' "$f" 2>/dev/null; done | \
awk '{sum+=$1} END {print "Total relationships:", sum}'

# Run tests
cd backend && PYTHONPATH=. pytest tests/test_eval_metrics.py tests/test_rag_pipeline.py --cov=app/eval
```

---

## Results Directory Structure

```
thesis/
├── config/
│   ├── corpus_manifest.jsonl    # PDF SHA256 hashes
│   ├── ground_truth_manifest.yaml
│   └── thresholds.yaml
├── results/
│   └── eval_YYYYMMDD.json       # Evaluation results with passed/violations
└── REPRODUCIBILITY.md           # This file
```

---

## Citation

If using this evaluation framework or corpus, please cite:

```
LAYRA Ethnopharmacology RAG System
Thesis Research Fork (2026)
https://github.com/liweiphys/layra (upstream)
```

---

*Generated by Sisyphus | OhMyOpenCode*
